{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Codeforces Scraper: Step-by-Step Explanation\n",
        "\n",
        "This scraper extracts problem details and editorial content from Codeforces. It uses Python with Selenium for web automation and BeautifulSoup for HTML parsing. The scraped data is stored locally in structured formats.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. **Configuration**\n",
        "   - **Directories:**\n",
        "     - `codeforces_scraper/problems` to store problem statements.\n",
        "     - `codeforces_scraper/editorials` to store editorial content.\n",
        "   - These directories are created using `os.makedirs()` to ensure they exist before storing data.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. **Selenium WebDriver Setup**\n",
        "   - **Headless Mode:** Configured to run in headless mode for efficiency.\n",
        "   - **Driver Installation:** `webdriver_manager` is used to install the appropriate ChromeDriver.\n",
        "   - **Binary Location:** The Chrome browser binary is explicitly specified to avoid driver location issues.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. **Helper Functions**\n",
        "### `save_to_file(directory, filename, content)`\n",
        "   - Saves content (HTML or text) to a specified file.\n",
        "   - Parameters:\n",
        "     - `directory`: Target directory.\n",
        "     - `filename`: Name of the file.\n",
        "     - `content`: The content to save.\n",
        "\n",
        "### `save_metadata(directory, metadata)`\n",
        "   - Saves problem metadata as a JSON file.\n",
        "   - Parameters:\n",
        "     - `directory`: Target directory.\n",
        "     - `metadata`: A dictionary containing metadata such as title, tags, time limit, and memory limit.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. **Scraping Functions**\n",
        "### `scrape_problem(driver, url)`\n",
        "   - **Process:**\n",
        "     1. Open the problem URL in the browser using Selenium.\n",
        "     2. Wait for the `problem-statement` element to load.\n",
        "     3. Parse the page with BeautifulSoup to extract:\n",
        "        - Title\n",
        "        - Problem statement\n",
        "        - Tags\n",
        "        - Time and memory limits\n",
        "     4. Save the problem statement in `.txt` format.\n",
        "     5. Save metadata in `metadata.json`.\n",
        "   - **Error Handling:** Catches and logs any exceptions encountered during scraping.\n",
        "\n",
        "### `scrape_editorial(driver, url)`\n",
        "   - **Process:**\n",
        "     1. Open the editorial URL in the browser using Selenium.\n",
        "     2. Wait for the `content` element to load.\n",
        "     3. Parse the page with BeautifulSoup to extract:\n",
        "        - Editorial title\n",
        "        - Main content\n",
        "     4. Save the editorial in `.txt` format.\n",
        "   - **Error Handling:** Catches and logs any exceptions encountered during scraping.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. **Main Program**\n",
        "   - **Problem URL:** Example problem URL from Codeforces.\n",
        "   - **Editorial URL:** Corresponding editorial URL.\n",
        "   - **Execution:**\n",
        "     1. Call `scrape_problem()` to extract problem details.\n",
        "     2. Call `scrape_editorial()` to extract editorial content.\n",
        "     3. Ensure the driver quits at the end, even if an error occurs.\n",
        "\n",
        "---\n",
        "\n",
        " 6. **Output**\n",
        "   - **Problem Statement:** Stored as a `.txt` file in the `problems` directory.\n",
        "   - **Metadata:** Stored as `metadata.json` in the `problems` directory.\n",
        "   - **Editorial Content:** Stored as a `.txt` file in the `editorials` directory.\n",
        "\n",
        "---\n",
        "\n",
        " 7. Dependencies\n",
        "   - Libraries:\n",
        "     - `os` and `json` for file handling.\n",
        "     - `BeautifulSoup` for HTML parsing.\n",
        "     - `Selenium` for web automation.\n",
        "     - `webdriver_manager` for managing the ChromeDriver.\n",
        "   - System Requirements:\n",
        "     - Chrome browser installed.\n",
        "     - Python packages installed via `pip`.\n",
        "\n",
        "---\n",
        "\n",
        " 8. Error Handling\n",
        "   - Gracefully handles errors during scraping and logs them for debugging.\n",
        "   - Ensures the browser driver is quit in case of exceptions.\n",
        "\n",
        "---\n",
        "\n",
        " Example Usage:\n",
        "To scrape a problem and its editorial:\n",
        "```python\n",
        "problem_url = \"https://codeforces.com/problemset/problem/1/A\"\n",
        "editorial_url = \"https://codeforces.com/blog/entry/1\"\n",
        "\n",
        "scrape_problem(driver, problem_url)\n",
        "scrape_editorial(driver, editorial_url)\n"
      ],
      "metadata": {
        "id": "96xetSuVOyYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0ztAkPEOv6k"
      },
      "outputs": [],
      "source": []
    }
  ]
}